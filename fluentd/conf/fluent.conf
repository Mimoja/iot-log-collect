<system>
  log_level warn
</system>

## ============================================================
## Sources
## ============================================================

# Edge device forward input (Fluent Bit on edge devices)
# Listens with TLS + shared_key for authentication.
# Receives both log records (tag: edge.**) and metric records
# (tag: metrics.**) from edge Fluent Bit forward outputs.
<source>
  @type forward
  port 24225
  bind 0.0.0.0
  <security>
    self_hostname sentry.meticulousespresso.com
    shared_key meticulous-edge-logs
  </security>
  <transport tls>
    cert_path /etc/letsencrypt/live/sentry.meticulousespresso.com/fullchain.pem
    private_key_path /etc/letsencrypt/live/sentry.meticulousespresso.com/privkey.pem
  </transport>
</source>

# Prometheus metrics endpoint for Fluentd itself
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type prometheus_monitor
</source>

<source>
  @type prometheus_output_monitor
</source>

## ============================================================
## Filters — edge device logs
## ============================================================

# --- Enrich with source and normalize severity ---
# Must run BEFORE remove_keys so that priority is still available for mapping
<filter edge.**>
  @type record_transformer
  enable_ruby true
  <record>
    source "edge"
    device_host ${record["hostname"] || "unknown"}
    device_unit ${record["systemd_unit"] || record["syslog_identifier"] || "unknown"}
    severity ${record["priority"] ? (begin; %w[emerg alert crit err warning notice info debug][record["priority"].to_i]; rescue; record["priority"] || "unknown"; end) : "unknown"}
  </record>
</filter>

# --- Drop noisy systemd metadata fields ---
# These cause ES mapping conflicts (e.g. cap_effective as hex string vs long)
# and are not useful for log analysis. priority is removed because severity
# already contains the human-readable version.
<filter edge.**>
  @type record_transformer
  remove_keys cap_effective,exe,cmdline,runtime_scope,systemd_cgroup,systemd_slice,systemd_invocation_id,stream_id,machine_id,boot_id,comm,transport,uid,gid,pid,syslog_facility,priority
</filter>

## ============================================================
## Filters — edge device metrics
## ============================================================

# Tag the metric type from the forwarded tag (metrics.cpu → cpu, etc.)
<filter metrics.**>
  @type record_transformer
  enable_ruby true
  <record>
    metric_type ${tag_parts[1]}
  </record>
</filter>

## ============================================================
## Outputs — edge device logs
## ============================================================

<match edge.**>
  @type copy

  # --- Store 1: Elasticsearch (existing) ---
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix edge
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  # --- Store 2: Loki ---
  <store>
    @type loki
    url http://loki:3100
    flush_interval 1s
    flush_at_shutdown true
    <label>
      source
      device_host
      device_unit
      severity
    </label>
    extra_labels {"job":"edge"}
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  # --- Store 3: stdout (debug) ---
  <store>
    @type stdout
  </store>
</match>

## ============================================================
## Outputs — edge device metrics → Loki
## ============================================================

<match metrics.**>
  @type loki
  url http://loki:3100
  flush_interval 5s
  flush_at_shutdown true
  <label>
    source
    device_host
    metric_type
  </label>
  extra_labels {"job":"edge-metrics"}
  <buffer>
    flush_mode interval
    flush_interval 5s
    retry_max_interval 30
    retry_forever true
  </buffer>
</match>

# --- Catch-all: discard anything else ---
<match **>
  @type null
</match>
