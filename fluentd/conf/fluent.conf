## ============================================================
## Sources
## ============================================================

# Docker forward input (containers using fluentd logging driver)
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker
</source>

# Edge device forward input (Fluent Bit on edge devices)
# Listens on a separate port with TLS + shared_key for authentication
<source>
  @type forward
  port 24225
  bind 0.0.0.0
  tag edge
  <security>
    self_hostname sentry.meticulousespresso.com
    shared_key meticulous-edge-logs
  </security>
  <transport tls>
    cert_path /fluentd/certs/fullchain.pem
    private_key_path /fluentd/certs/privkey.pem
  </transport>
</source>

# Systemd journal input (host journal mounted read-only)
<source>
  @type systemd
  tag systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /fluentd/log/systemd-cursor.json
  </storage>
  <entry>
    fields_strip_underscores true
    fields_lowercase true
  </entry>
  read_from_head false
</source>

# Sentry webhook receiver — point a Sentry internal integration webhook here
# Configure your Sentry project webhook to POST to http://<fluentd-host>:9880/sentry.events
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 2m
  keepalive_timeout 10s
  <parse>
    @type json
  </parse>
</source>

## ============================================================
## Filters
## ============================================================

# --- Systemd: enrich with severity label ---
<filter systemd.**>
  @type record_transformer
  enable_ruby true
  <record>
    severity ${record["priority"] ? (begin; %w[emerg alert crit err warning notice info debug][record["priority"].to_i]; rescue; record["priority"]; end) : "unknown"}
    source "systemd"
  </record>
</filter>

# --- Sentry: normalize event fields ---
<filter sentry.**>
  @type record_transformer
  enable_ruby true
  <record>
    source "sentry"
    severity ${record.dig("level") || record.dig("data","level") || "error"}
    sentry_event_id ${record.dig("data","event","event_id") || record.dig("id") || "unknown"}
    sentry_project ${record.dig("data","event","project") || record.dig("project_slug") || "unknown"}
    sentry_title ${record.dig("data","event","title") || record.dig("message") || "no title"}
    sentry_culprit ${record.dig("data","event","culprit") || "unknown"}
    sentry_url ${record.dig("data","event","web_url") || record.dig("url") || ""}
    sentry_platform ${record.dig("data","event","platform") || "unknown"}
  </record>
</filter>

# --- Docker containers: add source field ---
<filter docker.**>
  @type record_transformer
  <record>
    source "docker"
  </record>
</filter>

# --- Edge device journal: enrich with source and normalize severity ---
<filter edge.**>
  @type record_transformer
  enable_ruby true
  <record>
    source "edge"
    device_host ${record["hostname"] || "unknown"}
    device_unit ${record["systemd_unit"] || record["syslog_identifier"] || "unknown"}
    severity ${record["priority"] ? (begin; %w[emerg alert crit err warning notice info debug][record["priority"].to_i]; rescue; record["priority"] || "unknown"; end) : "unknown"}
  </record>
</filter>

## ============================================================
## Outputs
## ============================================================

# --- Systemd logs → separate ES index ---
<match systemd.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix systemd
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- Sentry events → separate ES index ---
<match sentry.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix sentry
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- Edge device journal logs → separate ES index ---
<match edge.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix edge
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- Docker / everything else → fluentd index ---
<match **>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix fluentd
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>
