## ============================================================
## Sources
## ============================================================

# Docker forward input (containers using fluentd logging driver)
<source>
  @type forward
  port 24224
  bind 0.0.0.0
  tag docker
</source>

# Systemd journal input (host journal mounted read-only)
<source>
  @type systemd
  tag systemd
  path /var/log/journal
  <storage>
    @type local
    persistent true
    path /fluentd/log/systemd-cursor.json
  </storage>
  <entry>
    fields_strip_underscores true
    fields_lowercase true
  </entry>
  read_from_head false
</source>

# Syslog input for remote IoT devices (TCP + UDP on port 5140)
# IoT devices running systemd can forward journal logs via
# systemd-journal-remote or rsyslog to this endpoint.
<source>
  @type syslog
  port 5140
  bind 0.0.0.0
  tag iot
  <transport tcp>
  </transport>
  <parse>
    message_format auto
  </parse>
</source>

<source>
  @type syslog
  port 5140
  bind 0.0.0.0
  protocol_type udp
  tag iot
  <parse>
    message_format auto
  </parse>
</source>

# Sentry webhook receiver — point a Sentry internal integration webhook here
# Configure your Sentry project webhook to POST to http://<fluentd-host>:9880/sentry.events
<source>
  @type http
  port 9880
  bind 0.0.0.0
  body_size_limit 2m
  keepalive_timeout 10s
  <parse>
    @type json
  </parse>
</source>

## ============================================================
## Filters
## ============================================================

# --- Systemd: enrich with severity label ---
<filter systemd.**>
  @type record_transformer
  enable_ruby true
  <record>
    severity ${record["priority"] ? %w[emerg alert crit err warning notice info debug][record["priority"].to_i] rescue record["priority"] : "unknown"}
    source "systemd"
  </record>
</filter>

# --- Sentry: normalize event fields ---
<filter sentry.**>
  @type record_transformer
  enable_ruby true
  <record>
    source "sentry"
    severity ${record.dig("level") || record.dig("data","level") || "error"}
    sentry_event_id ${record.dig("data","event","event_id") || record.dig("id") || "unknown"}
    sentry_project ${record.dig("data","event","project") || record.dig("project_slug") || "unknown"}
    sentry_title ${record.dig("data","event","title") || record.dig("message") || "no title"}
    sentry_culprit ${record.dig("data","event","culprit") || "unknown"}
    sentry_url ${record.dig("data","event","web_url") || record.dig("url") || ""}
    sentry_platform ${record.dig("data","event","platform") || "unknown"}
  </record>
</filter>

# --- Docker containers: add source field ---
<filter docker.**>
  @type record_transformer
  <record>
    source "docker"
  </record>
</filter>

# --- IoT syslog: enrich with source and normalize severity ---
<filter iot.**>
  @type record_transformer
  enable_ruby true
  <record>
    source "iot"
    device_host ${record["host"] || "unknown"}
    device_ident ${record["ident"] || "unknown"}
    severity ${record["priority"] ? %w[emerg alert crit err warning notice info debug][record["priority"].to_i] rescue (record["priority"] || "unknown")}
  </record>
</filter>

## ============================================================
## Outputs
## ============================================================

# --- Systemd logs → separate ES index ---
<match systemd.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix systemd
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- Sentry events → separate ES index ---
<match sentry.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix sentry
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- IoT device logs → separate ES index ---
<match iot.**>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix iot
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>

# --- Docker / everything else → fluentd index ---
<match **>
  @type copy

  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    user elastic
    password "#{ENV['ELASTIC_PASSWORD']}"
    logstash_format true
    logstash_prefix fluentd
    logstash_dateformat %Y%m%d
    include_tag_key true
    tag_key @log_name
    flush_interval 1s
    <buffer>
      flush_mode interval
      flush_interval 1s
      retry_max_interval 30
      retry_forever true
    </buffer>
  </store>

  <store>
    @type stdout
  </store>
</match>
